{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7aa027",
   "metadata": {},
   "source": [
    "# ¿Qué es un Árbol de Decisión?\n",
    "\n",
    "Un árbol de decisión es un modelo supervisado que puede usarse tanto para problemas de **clasificación** como de **regresión**. En esencia, funciona haciendo preguntas sucesivas sobre las características (features) de los datos, dividiendo el conjunto de datos en ramas hasta llegar a decisiones finales.\n",
    "\n",
    "* Las **ramas internas** del árbol representan condiciones sobre features (por ejemplo, “¿Kilometraje < 50000?”).\n",
    "* Cada división (“split”) divide los datos en subgrupos más homogéneos respecto de la variable objetivo.\n",
    "* Las **hojas** del árbol son las predicciones finales: pueden ser una clase en clasificación, o un valor continuo en regresión.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cómo funciona internamente?\n",
    "\n",
    "1. **Selección de la característica para dividir**:\n",
    "   Se buscan las características que mejor separan los datos con respecto al objetivo. Esto se mide por criterios como **gini impurity**, **entropía** o **ganancia de información**.\n",
    "\n",
    "2. **Punto de corte**:\n",
    "   Para variables numéricas, se busca un valor numérico tal que al dividir allí los datos, las partes resultantes sean lo más “puras” posibles.\n",
    "\n",
    "3. **Recursividad**:\n",
    "   Una vez que haces una división, ese proceso se repite para cada rama, usando los datos que quedaron en ella, hasta que se cumpla algún criterio de parada (por ejemplo, profundidad máxima, número mínimo de ejemplos en una hoja, pureza completa, etc.).\n",
    "\n",
    "4. **Predicción**:\n",
    "   Para clasificar o predecir una nueva observación, se comienza en la raíz del árbol, se evalúa la característica solicitada, se “camina” por la rama correspondiente, y se sigue hasta llegar a una hoja. Esa hoja indica la clase o valor asignado.\n",
    "\n",
    "---\n",
    "\n",
    "## Ventajas de los Árboles de Decisión\n",
    "\n",
    "* Son fáciles de entender e interpretar. Las reglas lógicas que usa el árbol son explícitas (“si esto y esto, entonces aquello”).\n",
    "* No necesitan mucha preparación de los datos (por ejemplo, no requieren normalización de features).\n",
    "* Pueden manejar tanto variables numéricas como categóricas.\n",
    "* Visualmente fáciles de representar, lo que facilita explicar los resultados a terceros.\n",
    "\n",
    "---\n",
    "\n",
    "## Desventajas o limitaciones\n",
    "\n",
    "* **Sobreajuste**: Los árboles que crecen demasiado pueden ajustar demasiado el ruido de los datos, en vez de capturar sólo la señal.\n",
    "* **Inestabilidad**: Pequeñas variaciones en los datos pueden generar árboles bastante diferentes.\n",
    "* Falta de suavidad en la predicción: el modelo produce saltos, porque las decisiones son en base a condiciones rígidas.\n",
    "* No suelen tener la mejor performance sin ajustes o sin combinarse con otros métodos (por ejemplo, Random Forests, boosting).\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Por qué es importante aprender Árboles de Decisión?\n",
    "\n",
    "* Porque es un modelo intuitivo que permite comprender reglas de decisión de forma clara. En muchos ámbitos, no basta con una predicción, sino que también se necesita **entender qué variables influyen** y cómo.\n",
    "* Son la base de muchos métodos más complejos: Random Forest, Gradient Boosting, XGBoost, etc. Para entender esos métodos híbridos, es útil partir de los árboles de decisión simples.\n",
    "* En problemas reales, pueden ser muy útiles si se busca transparencia o interpretabilidad, por ejemplo en decisiones financieras, médicas o de políticas.\n",
    "* Permiten hacer tanto clasificación como regresión, lo que los hace versátiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afc0c8",
   "metadata": {},
   "source": [
    "En los **árboles de decisión**, los **outliers tienen un impacto relativamente menor** que en modelos lineales, y esto es por varias razones:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **División basada en reglas de corte**\n",
    "\n",
    "* Los árboles deciden en cada nodo un **umbral** para dividir los datos (por ejemplo, “Kilometraje < 50.000”).\n",
    "* Un valor extremo solo afecta el nodo si cambia el punto de corte óptimo.\n",
    "* Si el outlier está lejos del rango mayoritario, normalmente termina en una hoja aparte y **no distorsiona toda la estructura del árbol**, como sí pasa en una regresión lineal.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Robustez relativa**\n",
    "\n",
    "* En modelos lineales, un solo outlier puede “tirar” la recta de ajuste hacia él.\n",
    "* En un árbol de decisión, los outliers suelen ser **aislados en hojas individuales**, por lo que no afectan tanto los splits del resto de los datos.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Limitaciones**\n",
    "\n",
    "* Aunque los árboles son robustos, **outliers extremos pueden generar hojas con muy pocos datos**, lo que puede llevar a **sobreajuste local**.\n",
    "* En datasets muy pequeños, incluso unos pocos outliers pueden cambiar la selección de un split.\n",
    "* En regresión de árboles (Decision Tree Regressor), los outliers pueden afectar la **predicción promedio** de una hoja si esa hoja contiene pocos datos.\n",
    "\n",
    "---\n",
    "\n",
    "##  Resumen práctico\n",
    "\n",
    "| Característica          | Árbol de Decisión                                       | Regresión Lineal                            |\n",
    "| ----------------------- | ------------------------------------------------------- | ------------------------------------------- |\n",
    "| Sensibilidad a outliers | Relativamente baja                                      | Alta, un outlier puede desviar la recta     |\n",
    "| Cómo afecta             | Puede crear hojas separadas                             | Cambia coeficientes y predicciones globales |\n",
    "| Precaución              | Outliers extremos en hojas pequeñas pueden sobreajustar | Necesario remover o transformar outliers    |\n",
    "\n",
    "---\n",
    "\n",
    "En conclusión:\n",
    "\n",
    "* Los árboles **no son inmunes**, pero manejan mejor los outliers que los modelos lineales clásicos.\n",
    "* Si los outliers son muy extremos o frecuentes, conviene revisar los datos o combinar con técnicas como **ensembles** (Random Forest o Gradient Boosting), que suavizan aún más su efecto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677458c",
   "metadata": {},
   "source": [
    "### Nombres\n",
    "\n",
    "1.  **buying** → **precio_compra**\n",
    "    *   *Explicación:* Representa el precio de compra del vehículo.\n",
    "    *   *Valores típicos:* `vhigh` (muy alto), `high` (alto), `med` (medio), `low` (bajo).\n",
    "\n",
    "2.  **maint** → **costo_mantenimiento**\n",
    "    *   *Explicación:* Representa el costo estimado del mantenimiento del vehículo.\n",
    "    *   *Valores típicos:* `vhigh` (muy alto), `high` (alto), `med` (medio), `low` (bajo).\n",
    "\n",
    "3.  **doors** → **numero_puertas**\n",
    "    *   *Explicación:* Indica el número de puertas del coche.\n",
    "    *   *Valores típicos:* `2`, `3`, `4`, `5more` (5 o más).\n",
    "\n",
    "4.  **persons** → **capacidad_pasajeros**\n",
    "    *   *Explicación:* Indica la capacidad de personas que el coche puede transportar.\n",
    "    *   *Valores típicos:* `2`, `4`, `more` (más de 4, típicamente 5 o 6).\n",
    "\n",
    "5.  **lug_boot** → **tamaño_maletero**\n",
    "    *   *Explicación:* Describe el tamaño del maletero o espacio de carga.\n",
    "    *   *Valores típicos:* `small` (pequeño), `med` (mediano), `big` (grande).\n",
    "\n",
    "6.  **safety** → **nivel_seguridad**\n",
    "    *   *Explicación:* Evalúa el nivel de seguridad estimado del vehículo.\n",
    "    *   *Valores típicos:* `low` (bajo), `med` (medio), `high` (alto).\n",
    "\n",
    "7.  **class** → **evaluacion_final** o **clase**\n",
    "    *   *Explicación:* Es la evaluación final o clasificación de aceptabilidad del coche.\n",
    "    *   *Valores típicos:* `unacc` (inaceptable), `acc` (aceptable), `good` (bueno), `vgood` (muy bueno).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"./datasets/car_evaluation.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_datos_car(df:pd.DataFrame, mapping:dict[str,dict]) -> pd. DataFrame:\n",
    "    # Crear copia del dataframe\n",
    "    df_normalizado = df.copy()\n",
    "    \n",
    "    for columna, mapeo in mapping.items():\n",
    "        if columna in df_normalizado.columns:\n",
    "            df_normalizado[columna] = df_normalizado[columna].map(mapeo)\n",
    "            \n",
    "    return df_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeo_categorias = {\n",
    "    # Precio de compra\n",
    "    'buying': {\n",
    "        'vhigh': 'muy_alto',\n",
    "        'high': 'alto', \n",
    "        'med': 'medio',\n",
    "        'low': 'bajo'\n",
    "    },\n",
    "    \n",
    "    # Costo de mantenimiento\n",
    "    'maint': {\n",
    "        'vhigh': 'muy_alto',\n",
    "        'high': 'alto',\n",
    "        'med': 'medio', \n",
    "        'low': 'bajo'\n",
    "    },\n",
    "    \n",
    "    # Número de puertas\n",
    "    'doors': {\n",
    "        '2': '2_puertas',\n",
    "        '3': '3_puertas',\n",
    "        '4': '4_puertas',\n",
    "        '5more': '5_o_mas_puertas'\n",
    "    },\n",
    "    \n",
    "    # Capacidad de pasajeros\n",
    "    'persons': {\n",
    "        '2': '2_pasajeros',\n",
    "        '4': '4_pasajeros',\n",
    "        'more': 'mas_de_4_pasajeros'\n",
    "    },\n",
    "    \n",
    "    # Tamaño del maletero\n",
    "    'lug_boot': {\n",
    "        'small': 'pequeno',\n",
    "        'med': 'mediano',\n",
    "        'big': 'grande'\n",
    "    },\n",
    "    \n",
    "    # Nivel de seguridad\n",
    "    'safety': {\n",
    "        'low': 'bajo',\n",
    "        'med': 'medio',\n",
    "        'high': 'alto'\n",
    "    },\n",
    "    \n",
    "    # Evaluación final\n",
    "    'class': {\n",
    "        'unacc': 'inaceptable',\n",
    "        'acc': 'aceptable',\n",
    "        'good': 'bueno',\n",
    "        'vgood': 'muy_bueno'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalizado = normalizar_datos_car(df=df,mapping=mapeo_categorias)\n",
    "df_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_especificas = {\n",
    "    'buying': 'precio',\n",
    "    'maint': 'mantenimiento',\n",
    "    'doors': 'num_puertas',\n",
    "    'persons': 'num_pasajeros',\n",
    "    'lug_boot': 'tamano_maletero',\n",
    "    'safety': 'seguridad',\n",
    "    'class': 'clase'\n",
    "}\n",
    "\n",
    "df = df_normalizado.rename(columns=columnas_especificas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d825e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=object).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5dd265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para FacetGrid\n",
    "df_melted = df.melt(var_name='variable', value_name='valor')\n",
    "\n",
    "# Crear FacetGrid\n",
    "g = sns.FacetGrid(\n",
    "    df_melted,\n",
    "    col='variable',\n",
    "    col_wrap=3, \n",
    "    sharex=False,\n",
    "    sharey=False,\n",
    "    height=4,\n",
    "    aspect=1.5\n",
    ")\n",
    "\n",
    "g.map_dataframe(sns.countplot, x='valor', palette='viridis', hue='valor')\n",
    "g.set_titles('{col_name}')\n",
    "g.set_xticklabels(rotation=45)\n",
    "\n",
    "# Ajustar layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Crear gráficos individuales y combinarlos\n",
    "charts = []\n",
    "\n",
    "for columna in df.columns:\n",
    "    chart = alt.Chart(df).mark_bar().encode(\n",
    "        x=alt.X(columna, title=columna, axis=alt.Axis(labelAngle=-45)),\n",
    "        y=alt.Y('count()', title='Frecuencia'),\n",
    "        tooltip=[columna, 'count()']\n",
    "    ).properties(\n",
    "        width=200,\n",
    "        height=200,\n",
    "        title=columna\n",
    "    )\n",
    "    charts.append(chart)\n",
    "\n",
    "# Combinar todos los gráficos\n",
    "final_chart = alt.vconcat(\n",
    "    alt.hconcat(*charts[0:3]),\n",
    "    alt.hconcat(*charts[3:6]),\n",
    "    alt.hconcat(charts[6], alt.Chart().mark_text(), alt.Chart().mark_text())  # Ajustar para 7 elementos\n",
    ")\n",
    "\n",
    "final_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194a020",
   "metadata": {},
   "source": [
    "## Separacion de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af23ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['clase'], axis=1)\n",
    "y = df['clase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc26f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Codificar X\n",
    "encoder_X = OrdinalEncoder()\n",
    "X_encoded = encoder_X.fit_transform(X)\n",
    "\n",
    "# Codificar y (si es categórico)\n",
    "encoder_y = LabelEncoder()\n",
    "y_encoded = encoder_y.fit_transform(y)\n",
    "\n",
    "# Dividir\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y_encoded, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parámetros estándar buenos para empezar\n",
    "dt_params = {\n",
    "    'criterion': 'gini',        # o 'entropy'\n",
    "    'max_depth': 5,             # controla sobreajuste\n",
    "    'min_samples_split': 20,    # mínimo muestras para dividir nodo\n",
    "    'min_samples_leaf': 10,     # mínimo muestras en hoja\n",
    "    'max_features': 'sqrt',     # características consideradas por split\n",
    "    'random_state': 42          # reproducibilidad\n",
    "}\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "dt_model = DecisionTreeClassifier(**dt_params)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred = dt_model.predict(X_test)\n",
    "y_pred_proba = dt_model.predict_proba(X_test)  # Probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03afc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(model, X_test, y_test, y_pred, encoder_y=None):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo con todas las métricas importantes\n",
    "    \"\"\"\n",
    "    print(\"EVALUACIÓN DEL MODELO\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Accuracy básico\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # 2. Métricas detalladas por clase\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                              target_names=encoder_y.classes_ if encoder_y else None,\n",
    "                              zero_division=0))\n",
    "    \n",
    "    # 3. Métricas macro (promedio no ponderado)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    print(f\"Precision (macro): {precision:.4f}\")\n",
    "    print(f\" Recall (macro): {recall:.4f}\")\n",
    "    print(f\"F1-Score (macro): {f1:.4f}\")\n",
    "    \n",
    "    # 4. Matriz de confusión visual\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Crear heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=encoder_y.classes_ if encoder_y else None,\n",
    "                yticklabels=encoder_y.classes_ if encoder_y else None)\n",
    "    \n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.ylabel('Valor Real')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902fe247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usar la función\n",
    "metricas = evaluar_modelo(dt_model, X_test, y_test, y_pred, encoder_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancias = dt_model.feature_importances_\n",
    "\n",
    "# Obtener nombres de características\n",
    "if hasattr(X, 'columns'):\n",
    "    caracteristicas = X.columns\n",
    "else:\n",
    "    caracteristicas = [f'Feature_{i}' for i in range(len(importancias))]\n",
    "\n",
    "# Crear DataFrame y ordenar por importancia\n",
    "df_importancias = pd.DataFrame({\n",
    "    'caracteristica': caracteristicas,\n",
    "    'importancia': importancias\n",
    "}).sort_values('importancia', ascending=True)  # Ordenar de menor a mayor para mejor visualización\n",
    "\n",
    "# Gráfico ordenado\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_importancias, x='importancia', y='caracteristica')\n",
    "plt.title('Importancia de Características (Ordenado por Importancia)')\n",
    "plt.xlabel('Importancia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar valores numéricos\n",
    "print(\"📊 IMPORTANCIA DE CARACTERÍSTICAS:\")\n",
    "print(df_importancias.sort_values('importancia', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a69e97",
   "metadata": {},
   "source": [
    "##  **Importancia de Características**\n",
    "\n",
    "**Ayuda a:**\n",
    "* [x] **Entender** qué variables realmente importan para predecir la calidad del auto\n",
    "* [x] **Simplificar** el modelo eliminando variables irrelevantes  \n",
    "* [x] **Comunicar** resultados a no-técnicos (\"La seguridad es el factor más importante\")\n",
    "* [x] **Optimizar** la recolección de datos futuros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ec7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "tree.plot_tree(\n",
    "    dt_model.fit(X_train, y_train),\n",
    "    feature_names=X.columns,\n",
    "    class_names=y.unique(),\n",
    "    filled=True\n",
    "    ) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28700ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "    dt_model,  # No necesitas .fit() again, el modelo ya está entrenado\n",
    "    out_file=None, \n",
    "    feature_names=X.columns, \n",
    "    class_names=encoder_y.classes_,  # Mejor usar encoder_y en lugar de y.unique()\n",
    "    filled=True,\n",
    "    rounded=True,  # Agregar para mejor apariencia\n",
    "    proportion=True  # Mostrar proporciones\n",
    ")\n",
    "\n",
    "# Draw graph con tamaño personalizado\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph.graph_attr = {\n",
    "    'size': '16,9',  # Tamaño 16x9 pulgadas\n",
    "    'dpi': '150'     # Resolución para mejor calidad\n",
    "}\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e173c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# Suprimir advertencias de fuentes\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Configurar fuentes del sistema\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Liberation Sans', 'Bitstream Vera Sans']\n",
    "\n",
    "from dtreeviz import model\n",
    "\n",
    "# Crear la visualización con parámetros CORRECTOS\n",
    "viz = model(dt_model,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            feature_names=list(X.columns),\n",
    "            target_name='clase',\n",
    "            class_names=list(encoder_y.classes_))\n",
    "\n",
    "# Visualizar\n",
    "viz.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "77695-data-science-i-flex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
