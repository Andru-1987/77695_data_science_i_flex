{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7aa027",
   "metadata": {},
   "source": [
    "# ¿Qué es un Árbol de Decisión?\n",
    "\n",
    "Un árbol de decisión es un modelo supervisado que puede usarse tanto para problemas de **clasificación** como de **regresión**. En esencia, funciona haciendo preguntas sucesivas sobre las características (features) de los datos, dividiendo el conjunto de datos en ramas hasta llegar a decisiones finales.\n",
    "\n",
    "* Las **ramas internas** del árbol representan condiciones sobre features (por ejemplo, “¿Kilometraje < 50000?”).\n",
    "* Cada división (“split”) divide los datos en subgrupos más homogéneos respecto de la variable objetivo.\n",
    "* Las **hojas** del árbol son las predicciones finales: pueden ser una clase en clasificación, o un valor continuo en regresión.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cómo funciona internamente?\n",
    "\n",
    "1. **Selección de la característica para dividir**:\n",
    "   Se buscan las características que mejor separan los datos con respecto al objetivo. Esto se mide por criterios como **gini impurity**, **entropía** o **ganancia de información**.\n",
    "\n",
    "2. **Punto de corte**:\n",
    "   Para variables numéricas, se busca un valor numérico tal que al dividir allí los datos, las partes resultantes sean lo más “puras” posibles.\n",
    "\n",
    "3. **Recursividad**:\n",
    "   Una vez que haces una división, ese proceso se repite para cada rama, usando los datos que quedaron en ella, hasta que se cumpla algún criterio de parada (por ejemplo, profundidad máxima, número mínimo de ejemplos en una hoja, pureza completa, etc.).\n",
    "\n",
    "4. **Predicción**:\n",
    "   Para clasificar o predecir una nueva observación, se comienza en la raíz del árbol, se evalúa la característica solicitada, se “camina” por la rama correspondiente, y se sigue hasta llegar a una hoja. Esa hoja indica la clase o valor asignado.\n",
    "\n",
    "---\n",
    "\n",
    "## Ventajas de los Árboles de Decisión\n",
    "\n",
    "* Son fáciles de entender e interpretar. Las reglas lógicas que usa el árbol son explícitas (“si esto y esto, entonces aquello”).\n",
    "* No necesitan mucha preparación de los datos (por ejemplo, no requieren normalización de features).\n",
    "* Pueden manejar tanto variables numéricas como categóricas.\n",
    "* Visualmente fáciles de representar, lo que facilita explicar los resultados a terceros.\n",
    "\n",
    "---\n",
    "\n",
    "## Desventajas o limitaciones\n",
    "\n",
    "* **Sobreajuste**: Los árboles que crecen demasiado pueden ajustar demasiado el ruido de los datos, en vez de capturar sólo la señal.\n",
    "* **Inestabilidad**: Pequeñas variaciones en los datos pueden generar árboles bastante diferentes.\n",
    "* Falta de suavidad en la predicción: el modelo produce saltos, porque las decisiones son en base a condiciones rígidas.\n",
    "* No suelen tener la mejor performance sin ajustes o sin combinarse con otros métodos (por ejemplo, Random Forests, boosting).\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Por qué es importante aprender Árboles de Decisión?\n",
    "\n",
    "* Porque es un modelo intuitivo que permite comprender reglas de decisión de forma clara. En muchos ámbitos, no basta con una predicción, sino que también se necesita **entender qué variables influyen** y cómo.\n",
    "* Son la base de muchos métodos más complejos: Random Forest, Gradient Boosting, XGBoost, etc. Para entender esos métodos híbridos, es útil partir de los árboles de decisión simples.\n",
    "* En problemas reales, pueden ser muy útiles si se busca transparencia o interpretabilidad, por ejemplo en decisiones financieras, médicas o de políticas.\n",
    "* Permiten hacer tanto clasificación como regresión, lo que los hace versátiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afc0c8",
   "metadata": {},
   "source": [
    "En los **árboles de decisión**, los **outliers tienen un impacto relativamente menor** que en modelos lineales, y esto es por varias razones:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **División basada en reglas de corte**\n",
    "\n",
    "* Los árboles deciden en cada nodo un **umbral** para dividir los datos (por ejemplo, “Kilometraje < 50.000”).\n",
    "* Un valor extremo solo afecta el nodo si cambia el punto de corte óptimo.\n",
    "* Si el outlier está lejos del rango mayoritario, normalmente termina en una hoja aparte y **no distorsiona toda la estructura del árbol**, como sí pasa en una regresión lineal.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Robustez relativa**\n",
    "\n",
    "* En modelos lineales, un solo outlier puede “tirar” la recta de ajuste hacia él.\n",
    "* En un árbol de decisión, los outliers suelen ser **aislados en hojas individuales**, por lo que no afectan tanto los splits del resto de los datos.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Limitaciones**\n",
    "\n",
    "* Aunque los árboles son robustos, **outliers extremos pueden generar hojas con muy pocos datos**, lo que puede llevar a **sobreajuste local**.\n",
    "* En datasets muy pequeños, incluso unos pocos outliers pueden cambiar la selección de un split.\n",
    "* En regresión de árboles (Decision Tree Regressor), los outliers pueden afectar la **predicción promedio** de una hoja si esa hoja contiene pocos datos.\n",
    "\n",
    "---\n",
    "\n",
    "##  Resumen práctico\n",
    "\n",
    "| Característica          | Árbol de Decisión                                       | Regresión Lineal                            |\n",
    "| ----------------------- | ------------------------------------------------------- | ------------------------------------------- |\n",
    "| Sensibilidad a outliers | Relativamente baja                                      | Alta, un outlier puede desviar la recta     |\n",
    "| Cómo afecta             | Puede crear hojas separadas                             | Cambia coeficientes y predicciones globales |\n",
    "| Precaución              | Outliers extremos en hojas pequeñas pueden sobreajustar | Necesario remover o transformar outliers    |\n",
    "\n",
    "---\n",
    "\n",
    "En conclusión:\n",
    "\n",
    "* Los árboles **no son inmunes**, pero manejan mejor los outliers que los modelos lineales clásicos.\n",
    "* Si los outliers son muy extremos o frecuentes, conviene revisar los datos o combinar con técnicas como **ensembles** (Random Forest o Gradient Boosting), que suavizan aún más su efecto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bb84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8f3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"./datasets/car_evaluation.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb05375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cfa6cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "77695-data-science-i-flex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
