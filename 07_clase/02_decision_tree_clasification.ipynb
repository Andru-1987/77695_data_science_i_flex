{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7aa027",
   "metadata": {},
   "source": [
    "# ¬øQu√© es un √Årbol de Decisi√≥n?\n",
    "\n",
    "Un √°rbol de decisi√≥n es un modelo supervisado que puede usarse tanto para problemas de **clasificaci√≥n** como de **regresi√≥n**. En esencia, funciona haciendo preguntas sucesivas sobre las caracter√≠sticas (features) de los datos, dividiendo el conjunto de datos en ramas hasta llegar a decisiones finales.\n",
    "\n",
    "* Las **ramas internas** del √°rbol representan condiciones sobre features (por ejemplo, ‚Äú¬øKilometraje < 50000?‚Äù).\n",
    "* Cada divisi√≥n (‚Äúsplit‚Äù) divide los datos en subgrupos m√°s homog√©neos respecto de la variable objetivo.\n",
    "* Las **hojas** del √°rbol son las predicciones finales: pueden ser una clase en clasificaci√≥n, o un valor continuo en regresi√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "## ¬øC√≥mo funciona internamente?\n",
    "\n",
    "1. **Selecci√≥n de la caracter√≠stica para dividir**:\n",
    "   Se buscan las caracter√≠sticas que mejor separan los datos con respecto al objetivo. Esto se mide por criterios como **gini impurity**, **entrop√≠a** o **ganancia de informaci√≥n**.\n",
    "\n",
    "2. **Punto de corte**:\n",
    "   Para variables num√©ricas, se busca un valor num√©rico tal que al dividir all√≠ los datos, las partes resultantes sean lo m√°s ‚Äúpuras‚Äù posibles.\n",
    "\n",
    "3. **Recursividad**:\n",
    "   Una vez que haces una divisi√≥n, ese proceso se repite para cada rama, usando los datos que quedaron en ella, hasta que se cumpla alg√∫n criterio de parada (por ejemplo, profundidad m√°xima, n√∫mero m√≠nimo de ejemplos en una hoja, pureza completa, etc.).\n",
    "\n",
    "4. **Predicci√≥n**:\n",
    "   Para clasificar o predecir una nueva observaci√≥n, se comienza en la ra√≠z del √°rbol, se eval√∫a la caracter√≠stica solicitada, se ‚Äúcamina‚Äù por la rama correspondiente, y se sigue hasta llegar a una hoja. Esa hoja indica la clase o valor asignado.\n",
    "\n",
    "---\n",
    "\n",
    "## Ventajas de los √Årboles de Decisi√≥n\n",
    "\n",
    "* Son f√°ciles de entender e interpretar. Las reglas l√≥gicas que usa el √°rbol son expl√≠citas (‚Äúsi esto y esto, entonces aquello‚Äù).\n",
    "* No necesitan mucha preparaci√≥n de los datos (por ejemplo, no requieren normalizaci√≥n de features).\n",
    "* Pueden manejar tanto variables num√©ricas como categ√≥ricas.\n",
    "* Visualmente f√°ciles de representar, lo que facilita explicar los resultados a terceros.\n",
    "\n",
    "---\n",
    "\n",
    "## Desventajas o limitaciones\n",
    "\n",
    "* **Sobreajuste**: Los √°rboles que crecen demasiado pueden ajustar demasiado el ruido de los datos, en vez de capturar s√≥lo la se√±al.\n",
    "* **Inestabilidad**: Peque√±as variaciones en los datos pueden generar √°rboles bastante diferentes.\n",
    "* Falta de suavidad en la predicci√≥n: el modelo produce saltos, porque las decisiones son en base a condiciones r√≠gidas.\n",
    "* No suelen tener la mejor performance sin ajustes o sin combinarse con otros m√©todos (por ejemplo, Random Forests, boosting).\n",
    "\n",
    "---\n",
    "\n",
    "## ¬øPor qu√© es importante aprender √Årboles de Decisi√≥n?\n",
    "\n",
    "* Porque es un modelo intuitivo que permite comprender reglas de decisi√≥n de forma clara. En muchos √°mbitos, no basta con una predicci√≥n, sino que tambi√©n se necesita **entender qu√© variables influyen** y c√≥mo.\n",
    "* Son la base de muchos m√©todos m√°s complejos: Random Forest, Gradient Boosting, XGBoost, etc. Para entender esos m√©todos h√≠bridos, es √∫til partir de los √°rboles de decisi√≥n simples.\n",
    "* En problemas reales, pueden ser muy √∫tiles si se busca transparencia o interpretabilidad, por ejemplo en decisiones financieras, m√©dicas o de pol√≠ticas.\n",
    "* Permiten hacer tanto clasificaci√≥n como regresi√≥n, lo que los hace vers√°tiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afc0c8",
   "metadata": {},
   "source": [
    "En los **√°rboles de decisi√≥n**, los **outliers tienen un impacto relativamente menor** que en modelos lineales, y esto es por varias razones:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **Divisi√≥n basada en reglas de corte**\n",
    "\n",
    "* Los √°rboles deciden en cada nodo un **umbral** para dividir los datos (por ejemplo, ‚ÄúKilometraje < 50.000‚Äù).\n",
    "* Un valor extremo solo afecta el nodo si cambia el punto de corte √≥ptimo.\n",
    "* Si el outlier est√° lejos del rango mayoritario, normalmente termina en una hoja aparte y **no distorsiona toda la estructura del √°rbol**, como s√≠ pasa en una regresi√≥n lineal.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Robustez relativa**\n",
    "\n",
    "* En modelos lineales, un solo outlier puede ‚Äútirar‚Äù la recta de ajuste hacia √©l.\n",
    "* En un √°rbol de decisi√≥n, los outliers suelen ser **aislados en hojas individuales**, por lo que no afectan tanto los splits del resto de los datos.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Limitaciones**\n",
    "\n",
    "* Aunque los √°rboles son robustos, **outliers extremos pueden generar hojas con muy pocos datos**, lo que puede llevar a **sobreajuste local**.\n",
    "* En datasets muy peque√±os, incluso unos pocos outliers pueden cambiar la selecci√≥n de un split.\n",
    "* En regresi√≥n de √°rboles (Decision Tree Regressor), los outliers pueden afectar la **predicci√≥n promedio** de una hoja si esa hoja contiene pocos datos.\n",
    "\n",
    "---\n",
    "\n",
    "##  Resumen pr√°ctico\n",
    "\n",
    "| Caracter√≠stica          | √Årbol de Decisi√≥n                                       | Regresi√≥n Lineal                            |\n",
    "| ----------------------- | ------------------------------------------------------- | ------------------------------------------- |\n",
    "| Sensibilidad a outliers | Relativamente baja                                      | Alta, un outlier puede desviar la recta     |\n",
    "| C√≥mo afecta             | Puede crear hojas separadas                             | Cambia coeficientes y predicciones globales |\n",
    "| Precauci√≥n              | Outliers extremos en hojas peque√±as pueden sobreajustar | Necesario remover o transformar outliers    |\n",
    "\n",
    "---\n",
    "\n",
    "En conclusi√≥n:\n",
    "\n",
    "* Los √°rboles **no son inmunes**, pero manejan mejor los outliers que los modelos lineales cl√°sicos.\n",
    "* Si los outliers son muy extremos o frecuentes, conviene revisar los datos o combinar con t√©cnicas como **ensembles** (Random Forest o Gradient Boosting), que suavizan a√∫n m√°s su efecto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677458c",
   "metadata": {},
   "source": [
    "### Nombres\n",
    "\n",
    "1.  **buying** ‚Üí **precio_compra**\n",
    "    *   *Explicaci√≥n:* Representa el precio de compra del veh√≠culo.\n",
    "    *   *Valores t√≠picos:* `vhigh` (muy alto), `high` (alto), `med` (medio), `low` (bajo).\n",
    "\n",
    "2.  **maint** ‚Üí **costo_mantenimiento**\n",
    "    *   *Explicaci√≥n:* Representa el costo estimado del mantenimiento del veh√≠culo.\n",
    "    *   *Valores t√≠picos:* `vhigh` (muy alto), `high` (alto), `med` (medio), `low` (bajo).\n",
    "\n",
    "3.  **doors** ‚Üí **numero_puertas**\n",
    "    *   *Explicaci√≥n:* Indica el n√∫mero de puertas del coche.\n",
    "    *   *Valores t√≠picos:* `2`, `3`, `4`, `5more` (5 o m√°s).\n",
    "\n",
    "4.  **persons** ‚Üí **capacidad_pasajeros**\n",
    "    *   *Explicaci√≥n:* Indica la capacidad de personas que el coche puede transportar.\n",
    "    *   *Valores t√≠picos:* `2`, `4`, `more` (m√°s de 4, t√≠picamente 5 o 6).\n",
    "\n",
    "5.  **lug_boot** ‚Üí **tama√±o_maletero**\n",
    "    *   *Explicaci√≥n:* Describe el tama√±o del maletero o espacio de carga.\n",
    "    *   *Valores t√≠picos:* `small` (peque√±o), `med` (mediano), `big` (grande).\n",
    "\n",
    "6.  **safety** ‚Üí **nivel_seguridad**\n",
    "    *   *Explicaci√≥n:* Eval√∫a el nivel de seguridad estimado del veh√≠culo.\n",
    "    *   *Valores t√≠picos:* `low` (bajo), `med` (medio), `high` (alto).\n",
    "\n",
    "7.  **class** ‚Üí **evaluacion_final** o **clase**\n",
    "    *   *Explicaci√≥n:* Es la evaluaci√≥n final o clasificaci√≥n de aceptabilidad del coche.\n",
    "    *   *Valores t√≠picos:* `unacc` (inaceptable), `acc` (aceptable), `good` (bueno), `vgood` (muy bueno).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"./datasets/car_evaluation.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_datos_car(df:pd.DataFrame, mapping:dict[str,dict]) -> pd. DataFrame:\n",
    "    # Crear copia del dataframe\n",
    "    df_normalizado = df.copy()\n",
    "    \n",
    "    for columna, mapeo in mapping.items():\n",
    "        if columna in df_normalizado.columns:\n",
    "            df_normalizado[columna] = df_normalizado[columna].map(mapeo)\n",
    "            \n",
    "    return df_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapeo_categorias = {\n",
    "    # Precio de compra\n",
    "    'buying': {\n",
    "        'vhigh': 'muy_alto',\n",
    "        'high': 'alto', \n",
    "        'med': 'medio',\n",
    "        'low': 'bajo'\n",
    "    },\n",
    "    \n",
    "    # Costo de mantenimiento\n",
    "    'maint': {\n",
    "        'vhigh': 'muy_alto',\n",
    "        'high': 'alto',\n",
    "        'med': 'medio', \n",
    "        'low': 'bajo'\n",
    "    },\n",
    "    \n",
    "    # N√∫mero de puertas\n",
    "    'doors': {\n",
    "        '2': '2_puertas',\n",
    "        '3': '3_puertas',\n",
    "        '4': '4_puertas',\n",
    "        '5more': '5_o_mas_puertas'\n",
    "    },\n",
    "    \n",
    "    # Capacidad de pasajeros\n",
    "    'persons': {\n",
    "        '2': '2_pasajeros',\n",
    "        '4': '4_pasajeros',\n",
    "        'more': 'mas_de_4_pasajeros'\n",
    "    },\n",
    "    \n",
    "    # Tama√±o del maletero\n",
    "    'lug_boot': {\n",
    "        'small': 'pequeno',\n",
    "        'med': 'mediano',\n",
    "        'big': 'grande'\n",
    "    },\n",
    "    \n",
    "    # Nivel de seguridad\n",
    "    'safety': {\n",
    "        'low': 'bajo',\n",
    "        'med': 'medio',\n",
    "        'high': 'alto'\n",
    "    },\n",
    "    \n",
    "    # Evaluaci√≥n final\n",
    "    'class': {\n",
    "        'unacc': 'inaceptable',\n",
    "        'acc': 'aceptable',\n",
    "        'good': 'bueno',\n",
    "        'vgood': 'muy_bueno'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalizado = normalizar_datos_car(df=df,mapping=mapeo_categorias)\n",
    "df_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_especificas = {\n",
    "    'buying': 'precio',\n",
    "    'maint': 'mantenimiento',\n",
    "    'doors': 'num_puertas',\n",
    "    'persons': 'num_pasajeros',\n",
    "    'lug_boot': 'tamano_maletero',\n",
    "    'safety': 'seguridad',\n",
    "    'class': 'clase'\n",
    "}\n",
    "\n",
    "df = df_normalizado.rename(columns=columnas_especificas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d825e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=object).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5dd265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para FacetGrid\n",
    "df_melted = df.melt(var_name='variable', value_name='valor')\n",
    "\n",
    "# Crear FacetGrid\n",
    "g = sns.FacetGrid(\n",
    "    df_melted,\n",
    "    col='variable',\n",
    "    col_wrap=3, \n",
    "    sharex=False,\n",
    "    sharey=False,\n",
    "    height=4,\n",
    "    aspect=1.5\n",
    ")\n",
    "\n",
    "g.map_dataframe(sns.countplot, x='valor', palette='viridis', hue='valor')\n",
    "g.set_titles('{col_name}')\n",
    "g.set_xticklabels(rotation=45)\n",
    "\n",
    "# Ajustar layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Crear gr√°ficos individuales y combinarlos\n",
    "charts = []\n",
    "\n",
    "for columna in df.columns:\n",
    "    chart = alt.Chart(df).mark_bar().encode(\n",
    "        x=alt.X(columna, title=columna, axis=alt.Axis(labelAngle=-45)),\n",
    "        y=alt.Y('count()', title='Frecuencia'),\n",
    "        tooltip=[columna, 'count()']\n",
    "    ).properties(\n",
    "        width=200,\n",
    "        height=200,\n",
    "        title=columna\n",
    "    )\n",
    "    charts.append(chart)\n",
    "\n",
    "# Combinar todos los gr√°ficos\n",
    "final_chart = alt.vconcat(\n",
    "    alt.hconcat(*charts[0:3]),\n",
    "    alt.hconcat(*charts[3:6]),\n",
    "    alt.hconcat(charts[6], alt.Chart().mark_text(), alt.Chart().mark_text())  # Ajustar para 7 elementos\n",
    ")\n",
    "\n",
    "final_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194a020",
   "metadata": {},
   "source": [
    "## Separacion de variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af23ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['clase'], axis=1)\n",
    "y = df['clase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc26f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Codificar X\n",
    "encoder_X = OrdinalEncoder()\n",
    "X_encoded = encoder_X.fit_transform(X)\n",
    "\n",
    "# Codificar y (si es categ√≥rico)\n",
    "encoder_y = LabelEncoder()\n",
    "y_encoded = encoder_y.fit_transform(y)\n",
    "\n",
    "# Dividir\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y_encoded, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Par√°metros est√°ndar buenos para empezar\n",
    "dt_params = {\n",
    "    'criterion': 'gini',        # o 'entropy'\n",
    "    'max_depth': 5,             # controla sobreajuste\n",
    "    'min_samples_split': 20,    # m√≠nimo muestras para dividir nodo\n",
    "    'min_samples_leaf': 10,     # m√≠nimo muestras en hoja\n",
    "    'max_features': 'sqrt',     # caracter√≠sticas consideradas por split\n",
    "    'random_state': 42          # reproducibilidad\n",
    "}\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "dt_model = DecisionTreeClassifier(**dt_params)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred = dt_model.predict(X_test)\n",
    "y_pred_proba = dt_model.predict_proba(X_test)  # Probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03afc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(model, X_test, y_test, y_pred, encoder_y=None):\n",
    "    \"\"\"\n",
    "    Eval√∫a el modelo con todas las m√©tricas importantes\n",
    "    \"\"\"\n",
    "    print(\"EVALUACI√ìN DEL MODELO\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Accuracy b√°sico\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # 2. M√©tricas detalladas por clase\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                              target_names=encoder_y.classes_ if encoder_y else None,\n",
    "                              zero_division=0))\n",
    "    \n",
    "    # 3. M√©tricas macro (promedio no ponderado)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    print(f\"Precision (macro): {precision:.4f}\")\n",
    "    print(f\" Recall (macro): {recall:.4f}\")\n",
    "    print(f\"F1-Score (macro): {f1:.4f}\")\n",
    "    \n",
    "    # 4. Matriz de confusi√≥n visual\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Crear heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=encoder_y.classes_ if encoder_y else None,\n",
    "                yticklabels=encoder_y.classes_ if encoder_y else None)\n",
    "    \n",
    "    plt.title('Matriz de Confusi√≥n')\n",
    "    plt.ylabel('Valor Real')\n",
    "    plt.xlabel('Predicci√≥n')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902fe247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usar la funci√≥n\n",
    "metricas = evaluar_modelo(dt_model, X_test, y_test, y_pred, encoder_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bce423",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancias = dt_model.feature_importances_\n",
    "\n",
    "# Obtener nombres de caracter√≠sticas\n",
    "if hasattr(X, 'columns'):\n",
    "    caracteristicas = X.columns\n",
    "else:\n",
    "    caracteristicas = [f'Feature_{i}' for i in range(len(importancias))]\n",
    "\n",
    "# Crear DataFrame y ordenar por importancia\n",
    "df_importancias = pd.DataFrame({\n",
    "    'caracteristica': caracteristicas,\n",
    "    'importancia': importancias\n",
    "}).sort_values('importancia', ascending=True)  # Ordenar de menor a mayor para mejor visualizaci√≥n\n",
    "\n",
    "# Gr√°fico ordenado\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_importancias, x='importancia', y='caracteristica')\n",
    "plt.title('Importancia de Caracter√≠sticas (Ordenado por Importancia)')\n",
    "plt.xlabel('Importancia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar valores num√©ricos\n",
    "print(\"üìä IMPORTANCIA DE CARACTER√çSTICAS:\")\n",
    "print(df_importancias.sort_values('importancia', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a69e97",
   "metadata": {},
   "source": [
    "##  **Importancia de Caracter√≠sticas**\n",
    "\n",
    "**Ayuda a:**\n",
    "* [x] **Entender** qu√© variables realmente importan para predecir la calidad del auto\n",
    "* [x] **Simplificar** el modelo eliminando variables irrelevantes  \n",
    "* [x] **Comunicar** resultados a no-t√©cnicos (\"La seguridad es el factor m√°s importante\")\n",
    "* [x] **Optimizar** la recolecci√≥n de datos futuros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ec7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "tree.plot_tree(\n",
    "    dt_model.fit(X_train, y_train),\n",
    "    feature_names=X.columns,\n",
    "    class_names=y.unique(),\n",
    "    filled=True\n",
    "    ) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28700ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "    dt_model,  # No necesitas .fit() again, el modelo ya est√° entrenado\n",
    "    out_file=None, \n",
    "    feature_names=X.columns, \n",
    "    class_names=encoder_y.classes_,  # Mejor usar encoder_y en lugar de y.unique()\n",
    "    filled=True,\n",
    "    rounded=True,  # Agregar para mejor apariencia\n",
    "    proportion=True  # Mostrar proporciones\n",
    ")\n",
    "\n",
    "# Draw graph con tama√±o personalizado\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph.graph_attr = {\n",
    "    'size': '16,9',  # Tama√±o 16x9 pulgadas\n",
    "    'dpi': '150'     # Resoluci√≥n para mejor calidad\n",
    "}\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e173c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# Suprimir advertencias de fuentes\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Configurar fuentes del sistema\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Liberation Sans', 'Bitstream Vera Sans']\n",
    "\n",
    "from dtreeviz import model\n",
    "\n",
    "# Crear la visualizaci√≥n con par√°metros CORRECTOS\n",
    "viz = model(dt_model,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            feature_names=list(X.columns),\n",
    "            target_name='clase',\n",
    "            class_names=list(encoder_y.classes_))\n",
    "\n",
    "# Visualizar\n",
    "viz.view()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "77695-data-science-i-flex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
